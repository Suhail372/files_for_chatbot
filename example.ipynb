{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import json\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VectorSearchWrapper:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.EMBED_MODEL = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "        self.model = SentenceTransformer(self.EMBED_MODEL, device=self.device)\n",
    "        self.json_file_path = 'combined files/cleaned_and_combined_hyd.json'\n",
    "        self.index = None\n",
    "        self.embeddings = []\n",
    "        self.id_to_entry = {}\n",
    "        self.run()\n",
    "\n",
    "    def embedding(self, text_data):\n",
    "        embedding = self.model.encode(text_data, convert_to_tensor=True, device=self.device)\n",
    "        normalized_embedding = torch.nn.functional.normalize(embedding, p=2, dim=-1)\n",
    "        return normalized_embedding.cpu().numpy()\n",
    "\n",
    "    def preprocess_and_embed(self):\n",
    "        embedded_list = []\n",
    "        with open(self.json_file_path, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "\n",
    "        for entry in json_data:\n",
    "            address = entry['Location']\n",
    "            terms = [term.strip() for term in address.split(',')]\n",
    "            replacable = ', '.join(terms[-4:]) if len(terms) > 4 else address\n",
    "            \n",
    "            entry['text data'] = entry['text data'].replace(address, replacable)\n",
    "            text_data = entry[\"text data\"].replace(f'Name: {entry[\"Name\"]}', '')\n",
    "            entry_id = entry.get(\"Id\", None)\n",
    "            \n",
    "            if entry_id is not None:\n",
    "                embedding = self.embedding(text_data)\n",
    "                embedded_list.append({\n",
    "                    \"embedding\": embedding,\n",
    "                    \"text\": text_data,\n",
    "                    \"id\": entry_id\n",
    "                })\n",
    "\n",
    "        return embedded_list\n",
    "\n",
    "    def create_faiss_index(self):\n",
    "        dimension = 384  # Embedding size of MiniLM\n",
    "        self.index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "    def insert_data(self):\n",
    "        self.create_faiss_index()\n",
    "        embeddings = np.vstack([entry[\"embedding\"] for entry in self.embeddings])\n",
    "        self.index.add(embeddings)\n",
    "\n",
    "    def run(self):\n",
    "        self.embeddings = self.preprocess_and_embed()\n",
    "        self.insert_data()\n",
    "\n",
    "    def search_faiss(self, query, k=3):\n",
    "        query_embedding = self.embedding(query).reshape(1, -1)\n",
    "        distances, indices = self.index.search(query_embedding, k)\n",
    "        \n",
    "        results = [{\"id\": self.embeddings[idx][\"id\"], \"text\": self.embeddings[idx][\"text\"]} for idx in indices[0]]\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_search = VectorSearchWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1912, 'text': '~Category: Public Schools~Location: Bolton Road, Opp. Tivoli Garden, Near JBS, Secunderabad-500003.~Faculty: ~Sports: Athletics, Tennis~Amenities: Laboratory, Computers Facility~Board: CBSE~Years: -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10~Fee: -1~Since: Not Available~Strength: Not Available~'}, {'id': 280, 'text': '~Category: Public Schools~Location: Beside Kalyani Theatre, Old Bowenpally, Hasmathpet, Secunderabad - 500011~Faculty: ~Sports: Athletics, Carroms, Chess, Karate, Skating, Yoga~Amenities: Transport, Laboratory, Smart Classrooms, Computers Facility, Library~Board: CBSE~Years: -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10~Fee: -1~Since: Not Available~Strength: Not Available~'}, {'id': 64, 'text': '~Category: Public Schools~Location: Saibaba Colony, Sitarampur, Bowenpally, Secunderabad - 500011.~Faculty: Mrs. T. Aruna Reddy Director~Sports: Athletics, Chess, Cricket, Football, Hockey, Swimming~Amenities: Transport, Laboratory, Smart Classrooms, Library~Board: CBSE~Years: -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12~Fee: -1~Since: 1999~Strength: Not Available~'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Override the search_faiss method if necessary\n",
    "# vector_search.search_faiss = new_search_faiss.__get__(vector_search, VectorSearchWrapper)\n",
    "\n",
    "# Call the method\n",
    "query = \"Schools in secunderabad\"\n",
    "results = vector_search.search_faiss(query)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1131\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test cases\n",
    "with open('testcases/two variable testcases.json', 'r') as file:\n",
    "    test_data = json.load(file)\n",
    "print(len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1157 4498 563\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p_count = 0\n",
    "crct_count = 0\n",
    "n_count = 0\n",
    "\n",
    "for dictionary in test_data:\n",
    "    data = vector_search.search_faiss(dictionary['query'],k=5)\n",
    "    test_res = [item['id'] for item in data]\n",
    "    stat = -1\n",
    "    for i in test_res:\n",
    "        if i in dictionary['ans']:\n",
    "            p_count += 1\n",
    "            stat = 0\n",
    "        else:\n",
    "            n_count += 1\n",
    "    if stat == 0:\n",
    "        crct_count += 1\n",
    "    stat = -1\n",
    "\n",
    "print(p_count, n_count, crct_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
